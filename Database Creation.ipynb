{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports all the relevant Modules\n",
    "from sqlalchemy import create_engine, inspect, Column, Integer, String\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String, Float, Date \n",
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "Base = declarative_base()\n",
    "\n",
    "#imports python modules\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "import requests\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establishes the connection\n",
    "MySQL_root_PW = 'Joseph155)'\n",
    "MySQL_db = 'gfc_data'\n",
    "\n",
    "\n",
    "engine = create_engine(\"mysql://root:\"+MySQL_root_PW+\"@localhost/\"+MySQL_db)\n",
    "conn = engine.connect()\n",
    "Base.metadata.create_all(engine)\n",
    "from sqlalchemy.orm import Session\n",
    "session = Session(bind=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "gfc_data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sqlalchemy\\util\\_collections.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gfc_data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-34092be9d903>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mGFC_Data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfc_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sqlalchemy\\util\\_collections.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: gfc_data"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builds the table in the database\n",
    "class econ_data_unemployment(Base):\n",
    "    __tablename__ = 'econ_unemployment'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    date = Column(Date)\n",
    "    Unemployment_Rate = Column(Float)\n",
    "\n",
    "class econ_data_new_orders(Base):\n",
    "    __tablename__ = 'econ_new_orders'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    date = Column(Date)\n",
    "    Value_of_Manufactuters_New_Orders = Column(Float)\n",
    "    \n",
    "class econ_data_non_defense(Base):\n",
    "    __tablename__ = 'econ_non_defense_x_air'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    date = Column(Date)\n",
    "    Manufacturers_New_Orders_Non_Defense_Cap_Goods_x_Air = Column(Float)\n",
    "    \n",
    "class econ_data_utilization(Base):\n",
    "    __tablename__ = 'econ_capacity_utilization'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    date = Column(Date)\n",
    "    Capacity_Utilization_Manufacturing = Column(Float)\n",
    "    \n",
    "class econ_data_claims(Base):\n",
    "    __tablename__ = 'econ_data_initial_claims'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    date = Column(Date)\n",
    "    Average_Weekly_Initial_Claims = Column(Float)\n",
    "    \n",
    "class econ_data_earnings(Base):\n",
    "    __tablename__ = 'econ_data_weekly_earnings'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    date = Column(Date)\n",
    "    Average_Weekly_Earnings = Column(Float)\n",
    "    \n",
    "#Creates the tables \n",
    "Base.metadata.tables\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports API Key\n",
    "api_key = \"5ec272d8e55ecfd7543c4dfcc0fdf45d\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_id = ['UNRATE', 'NEWORDER', 'ACOGNO', 'MCUMFN', 'ICSA', 'CES0500000011']\n",
    "class_id = ['econ_unemployment', \"econ_new_orders\", 'econ_non_defense_x_air', 'econ_capacity_utilization', 'econ_data_initial_claims', 'econ_data_weekly_earnings']\n",
    "data = ['Unemployment_Rate', 'Value_of_Manufactuters_New_Orders', 'Manufacturers_New_Orders_Non_Defense_Cap_Goods_x_Air', 'Capacity_Utilization_Manufacturing', 'Average_Weekly_Initial_Claims','Average_Weekly_Earnings']\n",
    "\n",
    "url_list = []\n",
    "length_list = []\n",
    "\n",
    "\n",
    "for series_id in series_id:\n",
    "    #Creates the Target URL\n",
    "    data_url = 'https://api.stlouisfed.org/fred/series/observations?series_id=' + series_id + '&api_key=' + api_key + '&file_type=json' \n",
    "    responses1 = requests.get(data_url).json()\n",
    "    length = responses1['count'] \n",
    "    url_list.append(data_url)\n",
    "    length_list.append(length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete 1\n",
      "Complete 2\n",
      "Complete 3\n",
      "Complete 4\n",
      "Complete 5\n",
      "Complete all\n"
     ]
    }
   ],
   "source": [
    "unemployment = requests.get(url_list[0]).json()\n",
    "for j in range(length_list[0]):\n",
    "    #Finds how many observations there are\n",
    "    df = pd.read_sql(\"SELECT id FROM \" + class_id[0], conn)\n",
    "    observations = df['id'].max()\n",
    "    \n",
    "    if j <= observations:\n",
    "        continue\n",
    "    else:\n",
    "        #Commits if no duplicates  \n",
    "        table = class_id[0]\n",
    "        date_output = unemployment['observations'][j]['date']  \n",
    "        data_output = unemployment['observations'][j]['value']\n",
    "        output = econ_data_unemployment(date=date_output, Unemployment_Rate=data_output)\n",
    "        session.add(output)\n",
    "        \n",
    "print(\"Complete 1\")\n",
    "\n",
    "new_orders = requests.get(url_list[1]).json()\n",
    "for k in range(length_list[1]):\n",
    "    #Finds how many observations there are\n",
    "    df = pd.read_sql(\"SELECT id FROM \" + class_id[1], conn)\n",
    "    observations = df['id'].max()\n",
    "    \n",
    "    if k <= observations:\n",
    "        continue\n",
    "    else: \n",
    "        try:\n",
    "            table = class_id[1]\n",
    "            date_output = new_orders['observations'][k]['date']\n",
    "            data_output = new_orders['observations'][k]['value']\n",
    "            if data_output != '.':\n",
    "                output = econ_data_new_orders(date=date_output, Value_of_Manufactuters_New_Orders=data_output)\n",
    "                session.add(output)\n",
    "            else :\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "print(\"Complete 2\")\n",
    "\n",
    "cap_goods = requests.get(url_list[2]).json()\n",
    "for l in range(length_list[2]):\n",
    "    #Finds how many observations there are\n",
    "    df = pd.read_sql(\"SELECT id FROM \" + class_id[2], conn)\n",
    "    observations = df['id'].max()\n",
    "    \n",
    "    if l <= observations:\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            table = class_id[2]\n",
    "            date_output = cap_goods['observations'][l]['date']\n",
    "            data_output = cap_goods['observations'][l]['value']\n",
    "            output = econ_data_non_defense(date=date_output, Manufacturers_New_Orders_Non_Defense_Cap_Goods_x_Air=data_output)\n",
    "            session.add(output)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "print(\"Complete 3\")\n",
    "\n",
    "cap_ut = requests.get(url_list[3]).json()\n",
    "for m in range(length_list[3]):\n",
    "    #Finds how many observations there are\n",
    "    df = pd.read_sql(\"SELECT id FROM \" + class_id[3], conn)\n",
    "    observations = df['id'].max()\n",
    "    \n",
    "    if n <= observations:\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            table = class_id[3]\n",
    "            date_output = cap_ut['observations'][m]['date']\n",
    "            data_output = cap_ut['observations'][m]['value']\n",
    "            output = econ_data_utilization(date=date_output, Capacity_Utilization_Manufacturing=data_output)\n",
    "            session.add(output)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "print(\"Complete 4\") \n",
    "\n",
    "initial_claims = requests.get(url_list[4]).json()\n",
    "for n in range(length_list[4]):\n",
    "    #Finds how many observations there are\n",
    "    df = pd.read_sql(\"SELECT id FROM \" + class_id[4], conn)\n",
    "    observations = df['id'].max()\n",
    "    \n",
    "    if n <= observations:\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            table = class_id[4]\n",
    "            date_output = initial_claims['observations'][n]['date']\n",
    "            data_output = initial_claims['observations'][n]['value']\n",
    "            output = econ_data_claims(date=date_output, Average_Weekly_Initial_Claims=data_output)\n",
    "            session.add(output)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print(\"Complete 5\")        \n",
    "\n",
    "weekly_earnings = requests.get(url_list[5]).json()\n",
    "for o in range(length_list[5]):\n",
    "    #Finds how many observations there are\n",
    "    df = pd.read_sql(\"SELECT id FROM \" + class_id[5], conn)\n",
    "    observations = df['id'].max()\n",
    "    \n",
    "    if o <= observations:\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            table = class_id[5]\n",
    "            date_output = weekly_earnings['observations'][o]['date']   \n",
    "            data_output = weekly_earnings['observations'][o]['value']\n",
    "            output = econ_data_earnings(date=date_output, Average_Weekly_Earnings=data_output)\n",
    "            session.add(output)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "#commits the data\n",
    "session.commit()\n",
    "        \n",
    "print(\"Complete all\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This section imports all data fed in through a csv file\n",
    "\n",
    "#reads the data\n",
    "Asset_returns = pd.read_excel('Resources/Asset Class Returns.xlsx')\n",
    "\n",
    "data_scheme = {\n",
    "    'Year': Date    \n",
    "}\n",
    "\n",
    "Asset_returns.to_sql(con=conn, dtype=data_scheme, name='asset_returns', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asset_returns',\n",
       " 'econ_capacity_utilization',\n",
       " 'econ_data_initial_claims',\n",
       " 'econ_data_weekly_earnings',\n",
       " 'econ_new_orders',\n",
       " 'econ_non_defense_x_air',\n",
       " 'econ_unemployment']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspector = inspect(engine)\n",
    "inspector.get_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['econ_capacity_utilization',\n",
       " 'econ_data_initial_claims',\n",
       " 'econ_data_weekly_earnings',\n",
       " 'econ_new_orders',\n",
       " 'econ_non_defense_x_air',\n",
       " 'econ_unemployment']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy.ext.automap import automap_base\n",
    "Base = automap_base()\n",
    "Base.prepare(engine, reflect=True)\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.date(1967, 1, 7), 208000.0, 685.37)\n",
      "(datetime.date(1967, 1, 14), 207000.0, 691.49)\n",
      "(datetime.date(1967, 1, 21), 217000.0, 690.8)\n",
      "(datetime.date(1967, 1, 28), 204000.0, 695.91)\n",
      "(datetime.date(1967, 2, 4), 216000.0, 698.32)\n",
      "(datetime.date(1967, 2, 11), 229000.0, 696.98)\n",
      "(datetime.date(1967, 2, 18), 229000.0, 702.1)\n",
      "(datetime.date(1967, 2, 25), 242000.0, 701.09)\n",
      "(datetime.date(1967, 3, 4), 310000.0, 704.86)\n",
      "(datetime.date(1967, 3, 11), 241000.0, 709.67)\n",
      "(datetime.date(1967, 3, 18), 245000.0, 706.58)\n",
      "(datetime.date(1967, 3, 25), 247000.0, 709.32)\n",
      "(datetime.date(1967, 4, 1), 259000.0, 713.11)\n",
      "(datetime.date(1967, 4, 8), 257000.0, 712.75)\n",
      "(datetime.date(1967, 4, 15), 299000.0, 716.9)\n",
      "(datetime.date(1967, 4, 22), 245000.0, 722.78)\n",
      "(datetime.date(1967, 4, 29), 255000.0, 721.02)\n",
      "(datetime.date(1967, 5, 6), 254000.0, 722.4)\n",
      "(datetime.date(1967, 5, 13), 231000.0, 724.12)\n",
      "(datetime.date(1967, 5, 20), 230000.0, 722.7)\n",
      "(datetime.date(1967, 5, 27), 228000.0, 726.53)\n",
      "(datetime.date(1967, 6, 3), 248000.0, 728.59)\n",
      "(datetime.date(1967, 6, 10), 238000.0, 729.28)\n",
      "(datetime.date(1967, 6, 17), 224000.0, 731.34)\n",
      "(datetime.date(1967, 6, 24), 218000.0, 734.78)\n",
      "(datetime.date(1967, 7, 1), 209000.0, 732.99)\n",
      "(datetime.date(1967, 7, 8), 240000.0, 738.91)\n",
      "(datetime.date(1967, 7, 15), 241000.0, 740.63)\n",
      "(datetime.date(1967, 7, 22), 240000.0, 740.88)\n",
      "(datetime.date(1967, 7, 29), 209000.0, 744.31)\n",
      "(datetime.date(1967, 8, 5), 221000.0, 743.17)\n",
      "(datetime.date(1967, 8, 12), 202000.0, 746.37)\n",
      "(datetime.date(1967, 8, 19), 215000.0, 746.11)\n",
      "(datetime.date(1967, 8, 26), 213000.0, 743.77)\n",
      "(datetime.date(1967, 9, 2), 218000.0, 746.98)\n",
      "(datetime.date(1967, 9, 9), 231000.0, 747.66)\n",
      "(datetime.date(1967, 9, 16), 220000.0, 745.63)\n",
      "(datetime.date(1967, 9, 23), 209000.0, 746.98)\n",
      "(datetime.date(1967, 9, 30), 204000.0, 747.32)\n",
      "(datetime.date(1967, 10, 7), 231000.0, 746.12)\n",
      "(datetime.date(1967, 10, 14), 206000.0, 749.68)\n",
      "(datetime.date(1967, 10, 21), 223000.0, 751.37)\n",
      "(datetime.date(1967, 10, 28), 207000.0, 754.61)\n",
      "(datetime.date(1967, 11, 4), 222000.0, 754.08)\n",
      "(datetime.date(1967, 11, 11), 214000.0, 758.0)\n",
      "(datetime.date(1967, 11, 18), 198000.0, 758.0)\n",
      "(datetime.date(1967, 11, 25), 191000.0, 764.52)\n",
      "(datetime.date(1967, 12, 2), 196000.0, 758.81)\n",
      "(datetime.date(1967, 12, 9), 221000.0, 763.64)\n",
      "(datetime.date(1967, 12, 16), 204000.0, 766.91)\n",
      "(datetime.date(1967, 12, 23), 219000.0, 768.27)\n",
      "(datetime.date(1967, 12, 30), 216000.0, 768.27)\n",
      "(datetime.date(1968, 1, 6), 222000.0, 770.32)\n",
      "(datetime.date(1968, 1, 13), 222000.0, 773.6)\n",
      "(datetime.date(1968, 1, 20), 221000.0, 777.58)\n",
      "(datetime.date(1968, 1, 27), 198000.0, 779.98)\n",
      "(datetime.date(1968, 2, 3), 244000.0, 777.37)\n",
      "(datetime.date(1968, 2, 10), 210000.0, 780.67)\n",
      "(datetime.date(1968, 2, 17), 196000.0, 781.47)\n",
      "(datetime.date(1968, 2, 24), 193000.0, 784.44)\n",
      "(datetime.date(1968, 3, 2), 190000.0, 784.78)\n",
      "(datetime.date(1968, 3, 9), 204000.0, 788.45)\n",
      "(datetime.date(1968, 3, 16), 190000.0, 788.56)\n",
      "(datetime.date(1968, 3, 23), 200000.0, 789.24)\n",
      "(datetime.date(1968, 3, 30), 192000.0, 794.98)\n",
      "(datetime.date(1968, 4, 6), 191000.0, 791.3)\n",
      "(datetime.date(1968, 4, 13), 171000.0, 794.98)\n",
      "(datetime.date(1968, 4, 20), 183000.0, 798.42)\n",
      "(datetime.date(1968, 4, 27), 251000.0, 797.74)\n",
      "(datetime.date(1968, 5, 4), 209000.0, 798.42)\n",
      "(datetime.date(1968, 5, 11), 194000.0, 801.78)\n",
      "(datetime.date(1968, 5, 18), 199000.0, 803.16)\n",
      "(datetime.date(1968, 5, 25), 194000.0, 803.58)\n",
      "(datetime.date(1968, 6, 1), 199000.0, 807.3)\n",
      "(datetime.date(1968, 6, 8), 192000.0, 804.96)\n",
      "(datetime.date(1968, 6, 15), 194000.0, 807.37)\n",
      "(datetime.date(1968, 6, 22), 189000.0, 809.09)\n",
      "(datetime.date(1968, 6, 29), 194000.0, 808.4)\n",
      "(datetime.date(1968, 7, 6), 214000.0, 811.15)\n",
      "(datetime.date(1968, 7, 13), 186000.0, 810.46)\n",
      "(datetime.date(1968, 7, 20), 180000.0, 812.87)\n",
      "(datetime.date(1968, 7, 27), 205000.0, 818.69)\n",
      "(datetime.date(1968, 8, 3), 206000.0, 817.34)\n",
      "(datetime.date(1968, 8, 10), 218000.0, 820.41)\n",
      "(datetime.date(1968, 8, 17), 192000.0, 821.45)\n",
      "(datetime.date(1968, 8, 24), 193000.0, 821.47)\n",
      "(datetime.date(1968, 8, 31), 188000.0, 824.55)\n",
      "(datetime.date(1968, 9, 7), 189000.0, 826.97)\n",
      "(datetime.date(1968, 9, 14), 195000.0, 825.26)\n",
      "(datetime.date(1968, 9, 21), 191000.0, 829.04)\n",
      "(datetime.date(1968, 9, 28), 189000.0, 827.66)\n",
      "(datetime.date(1968, 10, 5), 185000.0, 828.7)\n",
      "(datetime.date(1968, 10, 12), 186000.0, 833.52)\n",
      "(datetime.date(1968, 10, 19), 191000.0, 831.45)\n",
      "(datetime.date(1968, 10, 26), 182000.0, 832.82)\n",
      "(datetime.date(1968, 11, 2), 181000.0, 834.18)\n",
      "(datetime.date(1968, 11, 9), 183000.0, 838.7)\n",
      "(datetime.date(1968, 11, 16), 192000.0, 839.73)\n",
      "(datetime.date(1968, 11, 23), 199000.0, 841.8)\n",
      "(datetime.date(1968, 11, 30), 162000.0, 843.18)\n",
      "(datetime.date(1968, 12, 7), 188000.0, 844.56)\n",
      "(datetime.date(1968, 12, 14), 195000.0, 849.43)\n",
      "(datetime.date(1968, 12, 21), 192000.0, 847.32)\n",
      "(datetime.date(1968, 12, 28), 223000.0, 850.47)\n",
      "(datetime.date(1969, 1, 4), 190000.0, 852.89)\n",
      "(datetime.date(1969, 1, 11), 191000.0, 852.89)\n",
      "(datetime.date(1969, 1, 18), 192000.0, 853.53)\n",
      "(datetime.date(1969, 1, 25), 193000.0, 857.73)\n",
      "(datetime.date(1969, 2, 1), 203000.0, 857.33)\n",
      "(datetime.date(1969, 2, 8), 197000.0, 858.71)\n",
      "(datetime.date(1969, 2, 15), 192000.0, 861.47)\n",
      "(datetime.date(1969, 2, 22), 192000.0, 862.16)\n",
      "(datetime.date(1969, 3, 1), 201000.0, 862.85)\n",
      "(datetime.date(1969, 3, 8), 191000.0, 868.11)\n",
      "(datetime.date(1969, 3, 15), 189000.0, 866.64)\n",
      "(datetime.date(1969, 3, 22), 181000.0, 871.92)\n",
      "(datetime.date(1969, 3, 29), 183000.0, 871.13)\n",
      "(datetime.date(1969, 4, 5), 182000.0, 871.47)\n",
      "(datetime.date(1969, 4, 12), 190000.0, 877.8)\n",
      "(datetime.date(1969, 4, 19), 187000.0, 873.42)\n",
      "(datetime.date(1969, 4, 26), 177000.0, 875.82)\n",
      "(datetime.date(1969, 5, 3), 177000.0, 878.58)\n",
      "(datetime.date(1969, 5, 10), 183000.0, 879.61)\n",
      "(datetime.date(1969, 5, 17), 179000.0, 882.02)\n",
      "(datetime.date(1969, 5, 24), 180000.0, 884.08)\n",
      "(datetime.date(1969, 5, 31), 187000.0, 882.54)\n",
      "(datetime.date(1969, 6, 7), 192000.0, 886.83)\n",
      "(datetime.date(1969, 6, 14), 182000.0, 889.93)\n",
      "(datetime.date(1969, 6, 21), 191000.0, 888.71)\n",
      "(datetime.date(1969, 6, 28), 203000.0, 891.99)\n",
      "(datetime.date(1969, 7, 5), 227000.0, 893.71)\n",
      "(datetime.date(1969, 7, 12), 210000.0, 894.54)\n",
      "(datetime.date(1969, 7, 19), 206000.0, 895.57)\n",
      "(datetime.date(1969, 7, 26), 192000.0, 900.25)\n",
      "(datetime.date(1969, 8, 2), 196000.0, 901.97)\n",
      "(datetime.date(1969, 8, 9), 203000.0, 904.03)\n",
      "(datetime.date(1969, 8, 16), 199000.0, 906.78)\n",
      "(datetime.date(1969, 8, 23), 199000.0, 907.82)\n",
      "(datetime.date(1969, 8, 30), 195000.0, 909.29)\n",
      "(datetime.date(1969, 9, 6), 182000.0, 910.57)\n",
      "(datetime.date(1969, 9, 13), 209000.0, 915.98)\n",
      "(datetime.date(1969, 9, 20), 195000.0, 919.08)\n",
      "(datetime.date(1969, 9, 27), 193000.0, 918.82)\n",
      "(datetime.date(1969, 10, 4), 193000.0, 922.88)\n",
      "(datetime.date(1969, 10, 11), 200000.0, 925.98)\n",
      "(datetime.date(1969, 10, 18), 199000.0, 928.05)\n",
      "(datetime.date(1969, 10, 25), 205000.0, 931.16)\n",
      "(datetime.date(1969, 11, 1), 198000.0, 933.23)\n",
      "(datetime.date(1969, 11, 8), 211000.0, 935.3)\n",
      "(datetime.date(1969, 11, 15), 197000.0, 939.44)\n",
      "(datetime.date(1969, 11, 22), 217000.0, 941.85)\n",
      "(datetime.date(1969, 11, 29), 202000.0, 943.58)\n",
      "(datetime.date(1969, 12, 6), 202000.0, 943.59)\n",
      "(datetime.date(1969, 12, 13), 222000.0, 949.79)\n",
      "(datetime.date(1969, 12, 20), 232000.0, 950.82)\n"
     ]
    }
   ],
   "source": [
    "Capacity_Utilization = Base.classes.econ_capacity_utilization\n",
    "Initial_Claims = Base.classes.econ_data_initial_claims\n",
    "Weekley_Earnings = Base.classes.econ_data_weekly_earnings\n",
    "New_orders = Base.classes.econ_new_orders\n",
    "Capital_Goods_ex_Defense_Aircraft = Base.classes.econ_non_defense_x_air\n",
    "Unemployment_Rate = Base.classes.econ_unemployment\n",
    "\n",
    "q = session.query(Initial_Claims.date, Initial_Claims.Average_Weekly_Initial_Claims, Weekley_Earnings.Average_Weekly_Earnings).filter(Initial_Claims.date == Weekley_Earnings.id)\n",
    "for rec in q:\n",
    "    print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
